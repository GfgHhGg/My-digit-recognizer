{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of training and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was taken from <a href=\"https://www.kaggle.com/c/digit-recognizer/data\">kaggle competition</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max 42000\n",
    "train_size = 32000\n",
    "validation_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.genfromtxt('mnist/train.csv',delimiter=',', skip_header=1, skip_footer=42000 - train_size)[:, 1:]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.genfromtxt('mnist/train.csv',delimiter=',', skip_header=1, skip_footer=42000 - train_size)[:, 0][:, np.newaxis]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_validation = np.genfromtxt('mnist/train.csv',\n",
    "                        delimiter=',', \n",
    "                        skip_header=1 + train_size, \n",
    "                        skip_footer=42000 - validation_size - train_size)[:, 1:]\n",
    "x_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = np.genfromtxt('mnist/train.csv',\n",
    "                        delimiter=',', \n",
    "                        skip_header=1 + train_size, \n",
    "                        skip_footer=42000 - validation_size - train_size)[:, 0][:,np.newaxis]\n",
    "y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size 28x28\n",
    "plt.imshow(np.array([x_train[9][i-28:i] for i in range(28,785, 28)]));\n",
    "y_train[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperbolic tangent\n",
    "def tanh(x):\n",
    "    return (math.e**x - math.e**-x) / (math.e**x + math.e**-x)\n",
    "\n",
    "# Derivative of hyperbolic tangent\n",
    "def d_tanh(x):\n",
    "    return 1 - tanh(x)**2\n",
    "\n",
    "# Softmax in output layer\n",
    "def softmax(x):\n",
    "    assert x.shape[1] == 10\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.sum(exps, axis=1)[:, np.newaxis]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizer:\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        self.layer1 = np.random.random((n_hidden_neurons,784)) - 0.5\n",
    "        self.b1 = np.random.random((n_hidden_neurons, 1)) - 0.5\n",
    "        self.act1 = tanh\n",
    "        self.d_act1 = d_tanh\n",
    "        self.layer2 = np.random.random((10,n_hidden_neurons)) - 0.5\n",
    "        self.b2 = np.random.random((10, 1)) - 0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x / 255\n",
    "        # (n_hidden_neurons, n_examples) = (n_hidden_neurons, 784) @ (n_examples, 784).T\n",
    "        x = self.layer1 @ x.T\n",
    "        # (n_hidden_neurons, n_examples) += (n_hidden_neurons, 1)\n",
    "        x += self.b1\n",
    "        self.summatory1 = x\n",
    "        # (n_hidden_neurons, n_examples)\n",
    "        x = self.act1(x)\n",
    "        # (10, n_examples) = (10, n_hidden_neurons) @ (n_hidden_neurons, n_examples)\n",
    "        x = self.layer2 @ x\n",
    "        # (10, n_examples) += (10, 1)\n",
    "        x += self.b2\n",
    "        self.summatory2 = x\n",
    "        # (10, n_examples).T = # (n_examples, 10)\n",
    "        return softmax(x.T)\n",
    "\n",
    "net = DigitRecognizer(100) # You can change number of neurnons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    return np.sum(net.forward(x).argmax(axis=1)[:,np.newaxis] == y) / len(y)\n",
    "accuracy(x_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_pred, y):\n",
    "    m = y.shape[0]\n",
    "    log_likelihood = -np.log(y_pred[range(m),y.reshape(m).astype(int)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "# derivative of cross entropy with softmax\n",
    "def d_ce(y_pred, y):\n",
    "    ans = np.zeros(y_pred.shape)\n",
    "    ans[range(len(y)), y.reshape(len(y)).astype(int)] = -1 + y_pred[range(len(y)), y.reshape(len(y)).astype(int)]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(net.forward(x_validation), y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning process (back propagation algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_without_softmax(net, x, y, lr):\n",
    "    y_pred = net.forward(x) # (n_examples, 10)\n",
    "    \n",
    "    error_2 = d_ce(y_pred, y) # (n_examples, 10)\n",
    "    net.b2 -= lr * np.sum(error_2 ,axis=0)[:,np.newaxis] # (10, 1)\n",
    "    # (10,n_hidden_neurons) -= lr *  (n_examples, 10).T @ (n_hidden_neurons, n_examples).T\n",
    "    net.layer2 -= lr * error_2.T @ net.act1(net.summatory1).T\n",
    "    \n",
    "    # (n_hidden_neurons, n_examples) = (10, n_hidden_neurons).T @ (n_examples, 10).T * (n_hidden_neurons, n_examples)\n",
    "    error_1 = net.layer2.T @ error_2.T * net.d_act1(net.summatory1)\n",
    "    net.b1 -= lr * np.sum(error_1 ,axis=1)[:,np.newaxis] # (n_hidden_neurons, 1)\n",
    "    # (n_hidden_neurons, 784) -= lr * (n_hidden_neurons, n_examples) @ (n_examples, 784)\n",
    "    net.layer1 -= lr * error_1 @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "n_epoch = 10\n",
    "batch_size = 2000\n",
    "for i in range(n_epoch):\n",
    "    for j in range(batch_size, train_size + 1, batch_size):\n",
    "        train_without_softmax(net, x_train[j - batch_size: j], y_train[j - batch_size: j], 0.00001)\n",
    "        sys.stdout.write(\"\\r\" + 'Now: ' + str(j) + ' from ' + str(train_size))\n",
    "        sys.stdout.flush()\n",
    "    print(\"\\r\",accuracy(x_validation, y_validation), \n",
    "            cross_entropy(net.forward(x_validation), y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = 0\n",
    "step = 8000\n",
    "d = 0\n",
    "for i in range(8000, 32001, step):\n",
    "    summ += accuracy(x_train[i-step:i], y_train[i-step:i])\n",
    "    d += 1\n",
    "print(summ / d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 71\n",
    "plt.imshow(np.array([x_train[n][i-28:i] for i in range(28,785, 28)]));\n",
    "print(int(y_train[n][0]), \" - answer\")\n",
    "print(net.forward(x_train[n][np.newaxis,]).argmax(), \" - network output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "image = mpimg.imread('mnist/mypicture.png')\n",
    "vector_img = np.array(1 - image[:,:, 0]) * 255\n",
    "plt.imshow(image);\n",
    "net.forward(vector_img.reshape(784)[np.newaxis,]).argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
